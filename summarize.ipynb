{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b93db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = \"0\"\n",
    "MAX_INDEX = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eb4e550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary CSV saved: ./results/summary/exp_summary_seed_0.csv\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# %% [markdown]\n",
    "# # 実験結果の要約（投稿割合＋投稿数）\n",
    "# 各 `post_result_*.csv` を読み込み、割合と投稿数を平滑化して軽量CSVにまとめます。\n",
    "\n",
    "# %%\n",
    "def smooth_list(values, window_size=100):\n",
    "    \"\"\"リストをwindow_sizeごとに平均化\"\"\"\n",
    "    smoothed = []\n",
    "    for i in range(0, len(values), window_size):\n",
    "        window = values[i:i+window_size]\n",
    "        if window:\n",
    "            smoothed.append(sum(window) / len(window))\n",
    "    return smoothed\n",
    "\n",
    "# %%\n",
    "def process_single_experiment(data_dir, bins, output_csv, max_index=MAX_INDEX, window_size=100):\n",
    "    \"\"\"1つの実験ディレクトリから post_result_*.csv をまとめる\"\"\"\n",
    "    ratios = {bin_name: [] for bin_name in bins}\n",
    "    counts = []\n",
    "    steps = []\n",
    "\n",
    "    for i in range(max_index + 1):\n",
    "        filepath = os.path.join(data_dir, f\"post_result_{i}.csv\")\n",
    "        if not os.path.isfile(filepath):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            row = df.iloc[0]\n",
    "            total = sum([int(row[bin_name]) for bin_name in bins])\n",
    "            if total == 0:\n",
    "                continue\n",
    "\n",
    "            # 各binの割合\n",
    "            for bin_name in bins:\n",
    "                ratios[bin_name].append(int(row[bin_name]) / total)\n",
    "\n",
    "            # 投稿数を別で保存\n",
    "            counts.append(int(row.get(\"sumOfPosts\", total)))  # sumOfPostsがあればそれを使う\n",
    "            steps.append(i)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[{i}] error: {e}\")\n",
    "\n",
    "    if not steps:\n",
    "        print(\"No data found!\")\n",
    "        return\n",
    "\n",
    "    # 平滑化\n",
    "    smoothed_steps = steps[::window_size]\n",
    "    smoothed_ratios = {bin_name: smooth_list(values, window_size) for bin_name, values in ratios.items()}\n",
    "    smoothed_counts = smooth_list(counts, window_size)\n",
    "\n",
    "    # CSVに保存\n",
    "    df_out = pd.DataFrame({\"step\": smoothed_steps, \"sumOfPosts\": smoothed_counts})\n",
    "    for bin_name in bins:\n",
    "        df_out[bin_name] = smoothed_ratios[bin_name]\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
    "    df_out.to_csv(output_csv, index=False)\n",
    "    print(f\"summary CSV saved: {output_csv}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 実行例\n",
    "\n",
    "# %%\n",
    "data_dir = \"./results/posts\"  # 個別実験のディレクトリ\n",
    "output_csv = \"./results/summary/exp_summary_seed_\" + seed + \".csv\"\n",
    "bins = [\"bin_0\", \"bin_1\", \"bin_2\", \"bin_3\", \"bin_4\"]\n",
    "window_size = 100\n",
    "\n",
    "process_single_experiment(data_dir, bins, output_csv, window_size=window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "409ccd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded rows: 10001 | columns: ['step', 'opinionVar', 'postOpinionVar', 'follow', 'unfollow', 'rewire', 'opinionAvg', 'feedPostOpinionMean_0', 'feedPostOpinionMean_1', 'feedPostOpinionMean_2', 'feedPostOpinionMean_3', 'feedPostOpinionMean_4', 'feedPostOpinionVar_0', 'feedPostOpinionVar_1', 'feedPostOpinionVar_2', 'feedPostOpinionVar_3', 'feedPostOpinionVar_4', 'cRateMean_0', 'cRateMean_1', 'cRateMean_2', 'cRateMean_3', 'cRateMean_4', 'cRateVar_0', 'cRateVar_1', 'cRateVar_2', 'cRateVar_3', 'cRateVar_4', 'highComfortRateNum_0', 'highComfortRateNum_1', 'highComfortRateNum_2', 'highComfortRateNum_3', 'highComfortRateNum_4']\n",
      "saved: ./results/summary/var_summary_seed_0.csv\n",
      "   step  opinionVar  postOpinionVar\n",
      "0     0    0.259819        0.223584\n",
      "1   100    0.213470        0.192459\n",
      "2   200    0.207535        0.178463\n",
      "3   300    0.205455        0.176574\n",
      "4   400    0.208381        0.178077\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # 単一実験の variance を平滑化して CSV にまとめる\n",
    "# - 対象: ./results/metrics/result_*.csv （1 実験ぶん）\n",
    "# - 出力: ./results/summary/exp_summary_seed_X.csv\n",
    "# - 処理: step で結合 → 時系列で並べ替え → 100step ごとに平均 → CSV 保存\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# ==== パラメータ ====\n",
    "DATA_DIR   = \"./results/metrics\"                  # この実験の metrics ディレクトリ\n",
    "OUTPUT_CSV = \"./results/summary/var_summary_seed_\" + seed + \".csv\"\n",
    "STEP_BIN   = 100                                   # 何ステップごとに集約するか\n",
    "MAX_STEP   = MAX_INDEX                                # 例: 5000 にすると 5000 までに制限。制限不要なら None\n",
    "\n",
    "# %% 読み込み\n",
    "def load_single_experiment_metrics(data_dir, max_step=None):\n",
    "    files = sorted(glob.glob(os.path.join(data_dir, \"result_*.csv\")))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No result_*.csv in {data_dir}\")\n",
    "\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        try:\n",
    "            df = pd.read_csv(f)\n",
    "            if \"step\" not in df.columns:\n",
    "                continue\n",
    "            if max_step is not None:\n",
    "                df = df[df[\"step\"] <= max_step]\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"[skip] {f}: {e}\")\n",
    "\n",
    "    if not dfs:\n",
    "        raise ValueError(\"No readable CSVs were loaded.\")\n",
    "\n",
    "    out = pd.concat(dfs, ignore_index=True)\n",
    "    out = out.sort_values(\"step\").reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "raw_df = load_single_experiment_metrics(DATA_DIR, MAX_STEP)\n",
    "print(f\"loaded rows: {len(raw_df)} | columns: {list(raw_df.columns)}\")\n",
    "\n",
    "# %% variance 列だけ取り出して 100 step ごとに平均\n",
    "def summarize_variances(df, step_bin):\n",
    "    # 明示的に列を指定\n",
    "    var_cols = [\"opinionVar\", \"postOpinionVar\"]\n",
    "\n",
    "    # 存在チェック\n",
    "    for c in var_cols:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"Column {c} not found in input CSV\")\n",
    "\n",
    "    # step を bin にまとめる\n",
    "    df[\"step_bin\"] = (df[\"step\"] // step_bin) * step_bin\n",
    "\n",
    "    grouped = df.groupby(\"step_bin\")[var_cols].mean().reset_index()\n",
    "    grouped = grouped.rename(columns={\"step_bin\": \"step\"})\n",
    "    return grouped\n",
    "\n",
    "\n",
    "summary_df = summarize_variances(raw_df, STEP_BIN)\n",
    "\n",
    "# %% 保存\n",
    "os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)\n",
    "summary_df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"saved: {OUTPUT_CSV}\")\n",
    "print(summary_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3808311a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded rows: 10001 | columns: ['step', 'opinionVar', 'postOpinionVar', 'follow', 'unfollow', 'rewire', 'opinionAvg', 'feedPostOpinionMean_0', 'feedPostOpinionMean_1', 'feedPostOpinionMean_2', 'feedPostOpinionMean_3', 'feedPostOpinionMean_4', 'feedPostOpinionVar_0', 'feedPostOpinionVar_1', 'feedPostOpinionVar_2', 'feedPostOpinionVar_3', 'feedPostOpinionVar_4', 'cRateMean_0', 'cRateMean_1', 'cRateMean_2', 'cRateMean_3', 'cRateMean_4', 'cRateVar_0', 'cRateVar_1', 'cRateVar_2', 'cRateVar_3', 'cRateVar_4', 'highComfortRateNum_0', 'highComfortRateNum_1', 'highComfortRateNum_2', 'highComfortRateNum_3', 'highComfortRateNum_4']\n",
      "saved: ./results/summary/highCRNum_summary_seed_0.csv\n",
      "   step  highComfortRateNum_0  highComfortRateNum_1  highComfortRateNum_2  \\\n",
      "0     0                  7.89                 14.18                 31.67   \n",
      "1   100                 20.61                 24.86                 67.64   \n",
      "2   200                 20.22                 28.04                 68.63   \n",
      "3   300                 20.85                 23.62                 69.79   \n",
      "4   400                 18.50                 30.00                 64.95   \n",
      "\n",
      "   highComfortRateNum_3  highComfortRateNum_4  \n",
      "0                 33.99                 13.71  \n",
      "1                 61.05                 15.69  \n",
      "2                 50.25                 10.38  \n",
      "3                 46.92                 10.40  \n",
      "4                 45.89                  8.16  \n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # 単一実験の variance を平滑化して CSV にまとめる\n",
    "# - 対象: ./results/metrics/result_*.csv （1 実験ぶん）\n",
    "# - 出力: ./results/summary/exp_summary_seed_X.csv\n",
    "# - 処理: step で結合 → 時系列で並べ替え → 100step ごとに平均 → CSV 保存\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# ==== パラメータ ====\n",
    "DATA_DIR   = \"./results/metrics\"                  # この実験の metrics ディレクトリ\n",
    "OUTPUT_CSV = \"./results/summary/highCRNum_summary_seed_\" + seed + \".csv\"\n",
    "STEP_BIN   = 100                                   # 何ステップごとに集約するか\n",
    "MAX_STEP   = MAX_INDEX                               # 例: 5000 にすると 5000 までに制限。制限不要なら None\n",
    "\n",
    "# %% 読み込み\n",
    "def load_single_experiment_metrics(data_dir, max_step=None):\n",
    "    files = sorted(glob.glob(os.path.join(data_dir, \"result_*.csv\")))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No result_*.csv in {data_dir}\")\n",
    "\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        try:\n",
    "            df = pd.read_csv(f)\n",
    "            if \"step\" not in df.columns:\n",
    "                continue\n",
    "            if max_step is not None:\n",
    "                df = df[df[\"step\"] <= max_step]\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"[skip] {f}: {e}\")\n",
    "\n",
    "    if not dfs:\n",
    "        raise ValueError(\"No readable CSVs were loaded.\")\n",
    "\n",
    "    out = pd.concat(dfs, ignore_index=True)\n",
    "    out = out.sort_values(\"step\").reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "raw_df = load_single_experiment_metrics(DATA_DIR, MAX_STEP)\n",
    "print(f\"loaded rows: {len(raw_df)} | columns: {list(raw_df.columns)}\")\n",
    "\n",
    "# %% variance 列だけ取り出して 100 step ごとに平均\n",
    "def summarize_variances(df, step_bin):\n",
    "    # 明示的に列を指定\n",
    "    var_cols = [\"highComfortRateNum_0\", \"highComfortRateNum_1\", \"highComfortRateNum_2\", \"highComfortRateNum_3\", \"highComfortRateNum_4\"]\n",
    "\n",
    "    # 存在チェック\n",
    "    for c in var_cols:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"Column {c} not found in input CSV\")\n",
    "\n",
    "    # step を bin にまとめる\n",
    "    df[\"step_bin\"] = (df[\"step\"] // step_bin) * step_bin\n",
    "\n",
    "    grouped = df.groupby(\"step_bin\")[var_cols].mean().reset_index()\n",
    "    grouped = grouped.rename(columns={\"step_bin\": \"step\"})\n",
    "    return grouped\n",
    "\n",
    "\n",
    "summary_df = summarize_variances(raw_df, STEP_BIN)\n",
    "\n",
    "# %% 保存\n",
    "os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)\n",
    "summary_df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"saved: {OUTPUT_CSV}\")\n",
    "print(summary_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35601fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
